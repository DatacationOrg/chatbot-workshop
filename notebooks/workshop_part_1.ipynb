{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From LLM to agent\n",
    "\n",
    "In this workshop, we will incrementally build a powerful agent-based chatbot.\n",
    "\n",
    "This notebook will guide you through the steps, but some parts are left as exercises for you to complete.\n",
    "REMEMBER: The notebook is just there to experiment; the end result needs to be present in `chat_app.py` to be able to interactively chat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the basic chatbot\n",
    "\n",
    "We will begin by creating a basic chatbot using the `ChatGoogleGenerativeAI` model.\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "- Open the file `chat_app.py`.\n",
    "- Review the code and understand how the `on_message` function streams responses from the LLM.\n",
    "- Run the chatbot using the `main()` function and test it with some sample inputs.\n",
    "- Consider what the `AsyncLangchainCallbackHandler` does to monitor what's going on\n",
    "\n",
    "### Questions to consider:\n",
    "\n",
    "- How does the `astream` method work?\n",
    "- What is the role of `RunnableConfig`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-04-17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From LangChain to LangGraph\n",
    "\n",
    "To start building a proper agent, we need to migrate from LangChain to LangGraph.\n",
    "This will provide us with a thread-based message history with minimal configuration (the ability to ask follow-up questions).\n",
    "\n",
    "Check\n",
    "\n",
    "- https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/\n",
    "- https://langchain-ai.github.io/langgraph/agents/agents/#basic-configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(llm=llm, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding memory and checkpointing\n",
    "\n",
    "Use `InMemorySaver` to checkpoint (remember) conversations.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
