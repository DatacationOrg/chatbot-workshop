{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent to EDA assistent\n",
    "\n",
    "In this second part, we will expand on the agent and add abilities (tools) to inspect a certain dataset.\n",
    "\n",
    "This notebook will guide you through the steps, but some parts are left as exercises for you to complete.\n",
    "\n",
    "> REMEMBER: The notebook is just there to experiment; the end result needs to be present in `chat_app.py` to be able to interactively chat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# We need to add some necessary dependencies\n",
    "\n",
    "uv add datasets pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "The Titanic dataset is a wellknown standard dataset denoting the passengers of the Titanic. It is primarily used for causality regarding the survival rate.\n",
    "\n",
    "To load the Titanic dataset, we use the `load_dataset` function from the `datasets` library. This function allows us to easily access and convert the dataset into a pandas DataFrame for further analysis. The Titanic dataset is available at [Hugging Face Datasets](https://huggingface.co/datasets/mstz/titanic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mstz/titanic\")[\"train\"]\n",
    "titanic_df: pd.DataFrame = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain's SQL Database Integration\n",
    "\n",
    "In this section, we will explore how to leverage LangChain's SQL Database integration to interact with and analyze structured data. LangChain provides a seamless way to connect to SQL databases, execute queries, and retrieve results for further processing.\n",
    "\n",
    "The integration allows us to:\n",
    "\n",
    "- Connect to various SQL databases using supported drivers.\n",
    "- Perform complex queries to extract insights from the data.\n",
    "- Combine SQL capabilities with LangChain's tools for advanced data manipulation and analysis.\n",
    "\n",
    "For more details, refer to the [LangChain SQL Database Integration Documentation](https://python.langchain.com/docs/integrations/tools/sql_database/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires some glue code to load the pandas DataFrame into the in-memory SQLite database.\n",
    "titanic_df.to_sql(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the tools available to the ReAct agent\n",
    "\n",
    "- Ensure the agent can query the dataset using SQL commands.\n",
    "- Test the agent's ability to summarize the dataset.\n",
    "- Verify the agent can calculate statistics like mean, median, and mode.\n",
    "- Check if the agent can handle missing data gracefully.\n",
    "\n",
    "### Example Questions to Ask:\n",
    "\n",
    "- \"How many passengers survived the Titanic disaster?\"\n",
    "- \"What is the average age of the passengers?\"\n",
    "- \"List all passengers who embarked from Southampton.\"\n",
    "- \"What is the survival rate for male and female passengers?\"\n",
    "- \"Show the top 5 oldest passengers and their survival status.\"\n",
    "- Experiment with filtering data based specific conditions.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
